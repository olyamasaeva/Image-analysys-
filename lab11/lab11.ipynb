{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4f5077e7",
      "metadata": {
        "id": "4f5077e7"
      },
      "source": [
        "# Подготовка\n",
        " 1. Самостоятельно выбранными средствами (opencv, pillow (PIL), …) сгенерировать по 820 картинок размером 100х100 пикселей (px) для каждой из цифр: 0, 1, 3, 8 следующим образом (800 – тренировочная выборка, 20 – тестовая выборка № 1):\n",
        "    • фон картинки белый,\n",
        "    • цифра: ширина – 20 px, высота – 50 px, цвет линии – черный, цифра целиком помещается в картинку, цифра находится в случайном месте на картинке, \n",
        "    • на изображении цифра расположена так, что ее вертикальная ось параллельна оси ординат (вертикальное положение) или оси абсцисс (горизонтальное положение),\n",
        "    • тренировочная выборка содержит 400 изображений каждой цифры в горизонтальном положении и 400 изображений каждой цифры в вертикальном положении,\n",
        "    • тестовая выборка содержит 10 изображений каждой цифры в горизонтальном положении и 10 изображений каждой цифры в вертикальном положении,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69bd2033",
      "metadata": {
        "id": "69bd2033"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3c1a17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae3c1a17",
        "outputId": "068fc355-b6d3-43d0-f3ed-83da21a14681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable) \n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4391c9d",
      "metadata": {
        "id": "e4391c9d"
      },
      "outputs": [],
      "source": [
        "def print_img(img):\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Количество изображений для обучения\n",
        "nb_train_samples = 80\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 20\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 20\n",
        "n = nb_train_samples  + nb_validation_samples+nb_test_samples"
      ],
      "metadata": {
        "id": "D4I7EsPWyhLj"
      },
      "id": "D4I7EsPWyhLj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'thickness': 1,\n",
        "    'data_dir': r'./data',\n",
        "    'val_dir': r'./data/val',\n",
        "    'train_dir': r'./data/train',\n",
        "    'test_dir1': r'./data/test1',\n",
        "    'test_dir2': r'./data/test2',\n",
        "    'test_dir3': r'./data/test3',\n",
        "    'test_dir4': r'./data/test4',\n",
        "    'test_dir5': r'./data/test5',\n",
        "    'nb_images': n,\n",
        "}"
      ],
      "metadata": {
        "id": "whZW_rft1wQc"
      },
      "id": "whZW_rft1wQc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb8aeaa9",
      "metadata": {
        "id": "bb8aeaa9"
      },
      "outputs": [],
      "source": [
        "def draw0(dc, thickness):\n",
        "    cv2.ellipse(dc, ((10, 30), (19, 59), 0), (0, 0, 0), thickness)\n",
        "\n",
        "\n",
        "def draw1(dc, thickness):\n",
        "    cv2.line(dc, (0, 20), (19, 0), (0, 0, 0), thickness)\n",
        "    cv2.line(dc, (19, 0), (19, 59), (0, 0, 0), thickness)\n",
        "\n",
        "\n",
        "def draw3(dc, thickness):\n",
        "    cv2.ellipse(dc, (10, 22), (9, 9), 210, 0, 255, (0, 0, 0), thickness)\n",
        "    cv2.ellipse(dc, (10, 40), (9, 9), 255, 0, 255, (0, 0, 0), thickness)\n",
        "\n",
        "\n",
        "def draw8(dc, thickness):\n",
        "    cv2.ellipse(dc, (10, 22), (9, 9), 0, 0, 360, (0, 0, 0), thickness)\n",
        "    cv2.ellipse(dc, (10, 40), (9, 9), 0, 0, 360, (0, 0, 0), thickness)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b65772",
      "metadata": {
        "id": "b3b65772"
      },
      "outputs": [],
      "source": [
        "def create_digits(thickness):\n",
        "    _dc = {\n",
        "        0: np.ones((60, 20, 3), np.uint8) * 255,\n",
        "        1: np.ones((60, 20, 3), np.uint8) * 255,\n",
        "        3: np.ones((60, 20, 3), np.uint8) * 255,\n",
        "        8: np.ones((60, 20, 3), np.uint8) * 255,\n",
        "    }\n",
        "    draw0(_dc[0], thickness)\n",
        "    draw1(_dc[1], thickness)\n",
        "    draw3(_dc[3], thickness)\n",
        "    draw8(_dc[8], thickness)\n",
        "    return _dc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f44c269f",
      "metadata": {
        "id": "f44c269f"
      },
      "outputs": [],
      "source": [
        "def create_directory(dir_name):\n",
        "    if os.path.exists(dir_name):\n",
        "        shutil.rmtree(dir_name)\n",
        "    os.makedirs(dir_name)\n",
        "    os.makedirs(os.path.join(dir_name, \"0\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"1\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"3\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"8\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b03b75",
      "metadata": {
        "id": "e0b03b75"
      },
      "outputs": [],
      "source": [
        "def rand_point():\n",
        "    return np.random.randint(0, 79), np.random.randint(0, 39)\n",
        "\n",
        "\n",
        "def generate_dataset(d, _dc, _config):\n",
        "    for i in range(_config['nb_images']):\n",
        "        _canvas = np.ones((100, 100, 3), np.uint8) * 255\n",
        "        _x, _y = rand_point()\n",
        "        _canvas[_y:_y + _dc[d].shape[0], _x:_x + _dc[d].shape[1]] = _dc[d]\n",
        "        if (i >= nb_train_samples//2  and i < nb_train_samples) or (i >= nb_validation_samples//2 + nb_train_samples and i <nb_validation_samples + nb_train_samples)  or  i >= nb_train_samples +  nb_validation_samples  + nb_test_samples //2:\n",
        "            _canvas = np.rot90(_canvas)\n",
        "     #   if i == 501:\n",
        "      #      print_img(_canvas)\n",
        "        cv2.imwrite(os.path.join(config['data_dir'], str(d) + '_' + str(i) + \".jpg\"), _canvas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c713a42a",
      "metadata": {
        "id": "c713a42a"
      },
      "outputs": [],
      "source": [
        "def copy_images(start_index, end_index, source_dir, dest_dir):\n",
        "    for i in range(start_index, end_index):\n",
        "        shutil.copy2(os.path.join(source_dir, \"0_\" + str(i) + \".jpg\"),os.path.join(dest_dir, \"0\"))\n",
        "        shutil.copy2(os.path.join(source_dir, \"1_\" + str(i) + \".jpg\"),os.path.join(dest_dir, \"1\"))\n",
        "        shutil.copy2(os.path.join(source_dir, \"3_\" + str(i) + \".jpg\"),os.path.join(dest_dir, \"3\"))\n",
        "        shutil.copy2(os.path.join(source_dir, \"8_\" + str(i) + \".jpg\"),os.path.join(dest_dir, \"8\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4aa8d1",
      "metadata": {
        "id": "6b4aa8d1"
      },
      "outputs": [],
      "source": [
        "create_directory(config[\"train_dir\"])\n",
        "create_directory(config[\"val_dir\"])\n",
        "create_directory(config[\"test_dir1\"])\n",
        "create_directory(config[\"test_dir2\"])\n",
        "create_directory(config[\"test_dir3\"])\n",
        "create_directory(config[\"test_dir4\"])\n",
        "create_directory(config[\"test_dir5\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc11f76",
      "metadata": {
        "id": "bfc11f76"
      },
      "outputs": [],
      "source": [
        "dc = create_digits(config['thickness'])\n",
        "generate_dataset(0, dc, config)\n",
        "generate_dataset(1, dc, config)\n",
        "generate_dataset(3, dc, config)\n",
        "generate_dataset(8, dc, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3269e4ff",
      "metadata": {
        "id": "3269e4ff"
      },
      "outputs": [],
      "source": [
        "start_val_data_idx = nb_train_samples\n",
        "start_test_data_idx = nb_train_samples +  nb_validation_samples\n",
        "copy_images(0, start_val_data_idx, config['data_dir'], config['train_dir'])\n",
        "copy_images(start_val_data_idx, start_test_data_idx, config['data_dir'],  config['val_dir'])\n",
        "copy_images(start_test_data_idx, n, config['data_dir'],  config['test_dir1'])\n",
        "\n",
        "def pxl_gen(count, img):\n",
        "    for i in range(count):\n",
        "        x = np.random.randint(0, 100)\n",
        "        y = np.random.randint(0, 100)\n",
        "        img[x][y] = (0, 0, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9b50e10",
      "metadata": {
        "id": "b9b50e10"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fc9c7b2",
      "metadata": {
        "id": "3fc9c7b2"
      },
      "source": [
        "   2. Создать новые тестовые картинки, полученные путем добавления черных пикселей (шум) в случайно выбранные места сгенерированных тестовых картинок:\n",
        "    a) 20 px (тестовая выборка № 2),\n",
        "    b) 50 px (тестовая выборка № 3),\n",
        "    c) 100 px (тестовая выборка № 4),\n",
        "    d) 200 px (тестовая выборка № 5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f160ca0",
      "metadata": {
        "id": "1f160ca0"
      },
      "outputs": [],
      "source": [
        "for k in [0, 1, 3, 8]:\n",
        "    for i in range(nb_train_samples + nb_validation_samples , n):\n",
        "        fname = str(k) + \"_\" + str(i) + '.jpg'\n",
        "        # print(os.path.join(config[\"test_dir1\"], str(k), fname))\n",
        "        img = cv2.imread(os.path.join(config[\"test_dir1\"], str(k), fname))\n",
        "        dic = {2: 20, 3: 50, 4: 100, 5: 200}\n",
        "        for ntest, px in dic.items():\n",
        "            img_copy = img.copy()\n",
        "            pxl_gen(px, img_copy)\n",
        "            test_dir = \"test_dir\" + str(ntest)\n",
        "            cv2.imwrite(os.path.join(config[test_dir], str(k), fname), img_copy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7vkhbou-14rI"
      },
      "id": "7vkhbou-14rI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "38b2d044",
      "metadata": {
        "id": "38b2d044"
      },
      "source": [
        "# Задание \n",
        "Не используя предобученные модели (сети), модифицировать скрипт задачи «Dogs vs Cats» (из презентации лекции) или написать свою нейронную сеть на keras или torch такую, что:\n",
        "    1) На вход подается тренировочное множество: по 800 картинок каждой цифры.\n",
        "    2) Из тренировочного множества выделяется часть картинок (10–20%), на валидационное множество, в котором должны присутствовать цифры в вертикальном и горизонтальном положении. \n",
        "    3) Протестировать адекватность модели на всех тестовых выборках № 1, № 2, № 3, № 4, № 5, фиксируя при этом точность (accuracy) классификации.\n",
        "    4) Повторить пункты 1)–3), изменив объем тренировочной выборки до 600, 400, 200, 100 картинок каждой цифры.\n",
        "Результаты оформить в виде таблицы со столбцами: размер тренировочной выборки, количество шумовых пикселей, точность (accuracy) классификации. Полученные наборы изображений сохранить для следующих лабораторных работ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58341ba0",
      "metadata": {
        "id": "58341ba0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64264c8f",
      "metadata": {
        "id": "64264c8f"
      },
      "outputs": [],
      "source": [
        "data_dir = r'./data/train'\n",
        "# Каталог с данными для обучения\n",
        "train_dir = r'./data/train'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = r'./data/val'\n",
        "# Каталог с данными для тестирования\n",
        "test_dir = r'./data/test1'\n",
        "# Часть набора данных для тестирования\n",
        "test_data_portion = 0.15\n",
        "# Часть набора данных для проверки\n",
        "val_data_portion = 0.15\n",
        "# Количество элементов данных в одном классе\n",
        "nb_images = n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f660767",
      "metadata": {
        "id": "0f660767"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "t1 = time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8c13139",
      "metadata": {
        "id": "d8c13139"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Размеры изображения\n",
        "img_width, img_height = 100, 100\n",
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "# backend Tensorflow, channels_last\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Количество эпох\n",
        "epochs = 20\n",
        "# Размер мини-выборки\n",
        "batch_size = 20\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9bb346",
      "metadata": {
        "id": "8c9bb346"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем сверточную нейронную сеть. Архитектура сети:\n",
        "# Слой свертки, размер ядра 3х3, количество карт признаков - 32 шт., функция активации ReLU.\n",
        "# Слой подвыборки, выбор максимального значения из квадрата 2х2\n",
        "# Слой свертки, размер ядра 3х3, количество карт признаков - 32 шт., функция активации ReLU.\n",
        "# Слой подвыборки, выбор максимального значения из квадрата 2х2\n",
        "# Слой свертки, размер ядра 3х3, количество карт признаков - 64 шт., функция активации ReLU.\n",
        "# Слой подвыборки, выбор максимального значения из квадрата 2х2\n",
        "# Слой преобразования из двумерного в одномерное представление\n",
        "# Полносвязный слой, 64 нейрона,функция активации ReLU.\n",
        "# Слой Dropout.\n",
        "# Выходной слой, 1 нейрон, функция активации softmax\n",
        "# Слои с 1 по 6 используются для выделения важных признаков в изображении, а слои с 7 по 10 - для классификации.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4Py2pd_8KVn",
        "outputId": "6c7a6cee-7559-4302-cb21-f48f7d9bc70c"
      },
      "id": "Z4Py2pd_8KVn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 98, 98, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 49, 49, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 47, 47, 32)        9248      \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 47, 47, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 23, 23, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 21, 21, 64)        18496     \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 21, 21, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                409664    \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 260       \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 438,564\n",
            "Trainable params: 438,564\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e553ffc",
      "metadata": {
        "id": "6e553ffc"
      },
      "outputs": [],
      "source": [
        "# Компилируем нейронную сеть\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6804abeb",
      "metadata": {
        "id": "6804abeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05661a42-bc02-453c-d741-773efb8ceb6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 320 images belonging to 4 classes.\n",
            "Found 80 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Генератор изображений создается на основе класса ImageDataGenerator.\n",
        "# Генератор делит значения всех пикселов изображения на 255.\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# Генератор данных для обучения на основе изображений из каталога\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Генератор данных для проверки на основе изображений из каталога\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем модель с использованием генераторов\n",
        "# train_generator - генератор данных для обучения\n",
        "# validation_data - генератор данных для проверки\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tspPvAA4077h",
        "outputId": "23c62ff3-89d8-4613-9a10-05757a73b440"
      },
      "id": "tspPvAA4077h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 306ms/step - loss: 0.6469 - accuracy: 0.1875 - val_loss: 0.5789 - val_accuracy: 0.0500\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.6024 - accuracy: 0.2125 - val_loss: 0.5881 - val_accuracy: 0.1000\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.5922 - accuracy: 0.3000 - val_loss: 0.5606 - val_accuracy: 0.3500\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.5816 - accuracy: 0.2625 - val_loss: 0.5688 - val_accuracy: 0.2000\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.5766 - accuracy: 0.3375 - val_loss: 0.5587 - val_accuracy: 0.3500\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.5813 - accuracy: 0.2500 - val_loss: 0.5672 - val_accuracy: 0.3000\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.5833 - accuracy: 0.2500 - val_loss: 0.5712 - val_accuracy: 0.2500\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.5726 - accuracy: 0.3500 - val_loss: 0.5662 - val_accuracy: 0.1500\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.5852 - accuracy: 0.2625 - val_loss: 0.5650 - val_accuracy: 0.2500\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.5813 - accuracy: 0.1750 - val_loss: 0.5497 - val_accuracy: 0.3500\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.5706 - accuracy: 0.3125 - val_loss: 0.5518 - val_accuracy: 0.4000\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.5572 - accuracy: 0.3375 - val_loss: 0.5715 - val_accuracy: 0.2000\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.5765 - accuracy: 0.3250 - val_loss: 0.5485 - val_accuracy: 0.2500\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.5857 - accuracy: 0.1875 - val_loss: 0.5597 - val_accuracy: 0.3500\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.5741 - accuracy: 0.3000 - val_loss: 0.5572 - val_accuracy: 0.2500\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.5699 - accuracy: 0.2875 - val_loss: 0.5477 - val_accuracy: 0.3000\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.5742 - accuracy: 0.2750 - val_loss: 0.5557 - val_accuracy: 0.3000\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.5532 - accuracy: 0.3500 - val_loss: 0.5499 - val_accuracy: 0.3000\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.5381 - accuracy: 0.4375 - val_loss: 0.5803 - val_accuracy: 0.2000\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.5561 - accuracy: 0.3625 - val_loss: 0.5254 - val_accuracy: 0.3500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5ccb42f10>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "194e81c8",
      "metadata": {
        "id": "194e81c8"
      },
      "outputs": [],
      "source": [
        "def test_model(test_dir):\n",
        "  test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "  scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "  print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(r'./data/test1')\n",
        "test_model(\"./data/test2\")\n",
        "test_model(\"./data/test3\")\n",
        "test_model(\"./data/test4\")\n",
        "test_model(\"./data/test5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55UU-vyj1buE",
        "outputId": "d3f4cbe9-3759-403f-9d80-50d16c9857a9"
      },
      "id": "55UU-vyj1buE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Аккуратность на тестовых данных: 35.00%\n",
            "Found 80 images belonging to 4 classes.\n",
            "Аккуратность на тестовых данных: 35.00%\n",
            "Found 80 images belonging to 4 classes.\n",
            "Аккуратность на тестовых данных: 30.00%\n",
            "Found 80 images belonging to 4 classes.\n",
            "Аккуратность на тестовых данных: 25.00%\n",
            "Found 80 images belonging to 4 classes.\n",
            "Аккуратность на тестовых данных: 30.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04539a99",
      "metadata": {
        "id": "04539a99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "673e59d1-ee3c-4f8b-a517-220841fde32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.2385196685791\n"
          ]
        }
      ],
      "source": [
        "print(time() - t1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "lab11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}