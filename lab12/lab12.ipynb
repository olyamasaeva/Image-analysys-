{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4f5077e7",
      "metadata": {
        "id": "4f5077e7"
      },
      "source": [
        "# Задание 1\n",
        "Из наборов изображений, которые полученные в лабораторной работе № 11, выбрать по 135 изображений каждой цифры без шума: a)100/15/20 для обучающей/валидационной/тестовой выборок). В каждой выборке должно содержаться равное количество изображений каждой цифры в вертикальном и горизонтальном положении соответственно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69bd2033",
      "metadata": {
        "id": "69bd2033"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import sklearn\n",
        "import shutil\n",
        "import tensorflow\n",
        "from tensorflow import keras \n",
        "#from keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation, Flatten, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3c1a17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae3c1a17",
        "outputId": "903885e0-f49d-4999-d79c-afbc5d5bd313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable) \n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4391c9d",
      "metadata": {
        "id": "e4391c9d"
      },
      "outputs": [],
      "source": [
        "def print_img(img):\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Количество изображений для обучения\n",
        "nb_train_samples = 700\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 100\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 20\n",
        "n = nb_train_samples + nb_validation_samples + nb_test_samples "
      ],
      "metadata": {
        "id": "QJmu--cu-WMB"
      },
      "id": "QJmu--cu-WMB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'thickness': 1,\n",
        "    'data_dir': r'./data',\n",
        "    'val_dir': r'./data/val',\n",
        "    'train_dir': r'./data/train',\n",
        "    'test_dir1': r'./data/test1',\n",
        "    'test_dir2': r'./data/test2',\n",
        "    'test_dir3': r'./data/test3',\n",
        "    'test_dir4': r'./data/test4',\n",
        "    'test_dir5': r'./data/test5',\n",
        "    'nb_images': n,\n",
        "}"
      ],
      "metadata": {
        "id": "whZW_rft1wQc"
      },
      "id": "whZW_rft1wQc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "58MxPW_I-S6F"
      },
      "id": "58MxPW_I-S6F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb8aeaa9",
      "metadata": {
        "id": "bb8aeaa9"
      },
      "outputs": [],
      "source": [
        "def draw0(dc, thickness):\n",
        "    cv2.ellipse(dc, ((10, 30), (19, 59), 0), (0, 0, 0), thickness)\n",
        "\n",
        "\n",
        "def draw1(dc, thickness):\n",
        "    cv2.line(dc, (0, 20), (19, 0), (0, 0, 0), thickness)\n",
        "    cv2.line(dc, (19, 0), (19, 59), (0, 0, 0), thickness)\n",
        "\n",
        "\n",
        "def draw3(dc, thickness):\n",
        "    cv2.ellipse(dc, (10, 22), (9, 9), 210, 0, 255, (0, 0, 0), thickness)\n",
        "    cv2.ellipse(dc, (10, 40), (9, 9), 255, 0, 255, (0, 0, 0), thickness)\n",
        "\n",
        "\n",
        "def draw8(dc, thickness):\n",
        "    cv2.ellipse(dc, (10, 22), (9, 9), 0, 0, 360, (0, 0, 0), thickness)\n",
        "    cv2.ellipse(dc, (10, 40), (9, 9), 0, 0, 360, (0, 0, 0), thickness)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b65772",
      "metadata": {
        "id": "b3b65772"
      },
      "outputs": [],
      "source": [
        "def create_digits(thickness):\n",
        "    _dc = {\n",
        "        0: np.ones((60, 20, 3), np.uint8) * 255,\n",
        "        1: np.ones((60, 20, 3), np.uint8) * 255,\n",
        "        3: np.ones((60, 20, 3), np.uint8) * 255,\n",
        "        8: np.ones((60, 20, 3), np.uint8) * 255,\n",
        "    }\n",
        "    draw0(_dc[0], thickness)\n",
        "    draw1(_dc[1], thickness)\n",
        "    draw3(_dc[3], thickness)\n",
        "    draw8(_dc[8], thickness)\n",
        "    return _dc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f44c269f",
      "metadata": {
        "id": "f44c269f"
      },
      "outputs": [],
      "source": [
        "def create_directory(dir_name):\n",
        "    if os.path.exists(dir_name):\n",
        "        shutil.rmtree(dir_name)\n",
        "    os.makedirs(dir_name)\n",
        "    os.makedirs(os.path.join(dir_name, \"0\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"1\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"3\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"8\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b03b75",
      "metadata": {
        "id": "e0b03b75"
      },
      "outputs": [],
      "source": [
        "def rand_point():\n",
        "    return np.random.randint(0, 79), np.random.randint(0, 39)\n",
        "\n",
        "\n",
        "def generate_dataset(d, _dc, _config):\n",
        "    for i in range(_config['nb_images']):\n",
        "        _canvas = np.ones((100, 100, 3), np.uint8) * 255\n",
        "        _x, _y = rand_point()\n",
        "        _canvas[_y:_y + _dc[d].shape[0], _x:_x + _dc[d].shape[1]] = _dc[d]\n",
        "        if (i >= nb_train_samples//2  and i < nb_train_samples) or (i >= nb_validation_samples//2 + nb_train_samples and i <nb_validation_samples + nb_train_samples)  or  i >= nb_train_samples +  nb_validation_samples  + nb_test_samples //2:\n",
        "            _canvas = np.rot90(_canvas)\n",
        "     #   if i == 501:\n",
        "      #      print_img(_canvas)\n",
        "        cv2.imwrite(os.path.join(config['data_dir'], str(d) + '_' + str(i) + \".jpg\"), _canvas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c713a42a",
      "metadata": {
        "id": "c713a42a"
      },
      "outputs": [],
      "source": [
        "def copy_images(start_index, end_index, source_dir, dest_dir):\n",
        "    for i in range(start_index, end_index):\n",
        "        shutil.copy2(os.path.join(source_dir, \"0_\" + str(i) + \".jpg\"),os.path.join(dest_dir, \"0\"))\n",
        "        shutil.copy2(os.path.join(source_dir, \"1_\" + str(i) + \".jpg\"),os.path.join(dest_dir, \"1\"))\n",
        "        shutil.copy2(os.path.join(source_dir, \"3_\" + str(i) + \".jpg\"),os.path.join(dest_dir, \"3\"))\n",
        "        shutil.copy2(os.path.join(source_dir, \"8_\" + str(i) + \".jpg\"),os.path.join(dest_dir, \"8\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4aa8d1",
      "metadata": {
        "id": "6b4aa8d1"
      },
      "outputs": [],
      "source": [
        "create_directory(config[\"train_dir\"])\n",
        "create_directory(config[\"val_dir\"])\n",
        "create_directory(config[\"test_dir1\"])\n",
        "create_directory(config[\"test_dir2\"])\n",
        "create_directory(config[\"test_dir3\"])\n",
        "create_directory(config[\"test_dir4\"])\n",
        "create_directory(config[\"test_dir5\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc11f76",
      "metadata": {
        "id": "bfc11f76"
      },
      "outputs": [],
      "source": [
        "dc = create_digits(config['thickness'])\n",
        "generate_dataset(0, dc, config)\n",
        "generate_dataset(1, dc, config)\n",
        "generate_dataset(3, dc, config)\n",
        "generate_dataset(8, dc, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3269e4ff",
      "metadata": {
        "id": "3269e4ff"
      },
      "outputs": [],
      "source": [
        "start_val_data_idx = nb_train_samples\n",
        "start_test_data_idx =nb_train_samples + nb_validation_samples\n",
        "copy_images(0, start_val_data_idx, config['data_dir'], config['train_dir'])\n",
        "copy_images(start_val_data_idx, start_test_data_idx, config['data_dir'],  config['val_dir'])\n",
        "copy_images(start_test_data_idx, n, config['data_dir'],  config['test_dir1'])\n",
        "\n",
        "def pxl_gen(count, img):\n",
        "    for i in range(count):\n",
        "        x = np.random.randint(0, 100)\n",
        "        y = np.random.randint(0, 100)\n",
        "        img[x][y] = (0, 0, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9b50e10",
      "metadata": {
        "id": "b9b50e10"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fc9c7b2",
      "metadata": {
        "id": "3fc9c7b2"
      },
      "source": [
        "# Задание 2\n",
        "Используя keras или torch и по очереди каждую из сверточных нейронных сетей https://keras.io/api/applications/ : Xception, ResNet152V2, InceptionResNetV2, DenseNet201, NASNetLarge дообучить сеть на этих картинках и вывести результаты классификации на тестовом множестве."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f160ca0",
      "metadata": {
        "id": "1f160ca0"
      },
      "outputs": [],
      "source": [
        "data_dir = r'./data/train'\n",
        "# Каталог с данными для обучения\n",
        "train_dir = r'./data/train'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = r'./data/val'\n",
        "# Каталог с данными для тестирования\n",
        "test_dir = r'./data/test1'\n",
        "# Часть набора данных для тестирования\n",
        "test_data_portion = 0.15\n",
        "# Часть набора данных для проверки\n",
        "val_data_portion = 0.15\n",
        "# Количество элементов данных в одном классе\n",
        "nb_images = n\n",
        "# Размеры изображения\n",
        "img_width, img_height = 100, 100\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "# backend Tensorflow, channels_last\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Количество эпох\n",
        "epochs = 10\n",
        "# Размер мини-выборки\n",
        "batch_size = 15\n",
        "\n"
      ],
      "metadata": {
        "id": "S1tC2Ch9NGAN"
      },
      "id": "S1tC2Ch9NGAN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.xception import Xception\n",
        "\n",
        "# Модель\n",
        "#res_net50 = Xception(weights='imagenet',\n",
        " #                    include_top=False,\n",
        " #                    input_shape=input_shape,\n",
        " #                    classes=4,\n",
        " #                    pooling='avg')\n",
        "#res_net50 = tensorflow.keras.applications.ResNet152V2(weights='imagenet',\n",
        "#                   include_top=False,\n",
        "#                  input_shape=input_shape,\n",
        "#                classes=4,\n",
        "#               pooling='avg')\n",
        "#res_net50 = tensorflow.keras.applications.InceptionResNetV2(weights='imagenet',\n",
        "#                   include_top=False,\n",
        "#                  input_shape=input_shape,\n",
        "#                classes=4,\n",
        "#               pooling='avg')\n",
        "#res_net50 = tensorflow.keras.applications.DenseNet201(weights='imagenet',\n",
        "#                   include_top=False,\n",
        "#                  input_shape=input_shape,\n",
        "#                classes=4,\n",
        "#               pooling='avg')\n",
        "res_net50 = tensorflow.keras.applications.NASNetLarge(weights=None,include_top=False,input_shape=input_shape, classes=4,pooling='avg')\n",
        "res_net50.trainable = False"
      ],
      "metadata": {
        "id": "Kepj4jB7NSvG"
      },
      "id": "Kepj4jB7NSvG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras import Sequentia\n",
        "model = keras.Sequential()\n",
        "model.add(res_net50)\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr8wRfINNbAB",
        "outputId": "eb5c00d3-1b62-4e1e-e27f-03faa1573e70"
      },
      "id": "Cr8wRfINNbAB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " NASNet (Functional)         (None, 4032)              84916818  \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 4)                 16132     \n",
            "                                                                 \n",
            " activation_1868 (Activation  (None, 4)                0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,932,950\n",
            "Trainable params: 16,132\n",
            "Non-trainable params: 84,916,818\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компилируем нейронную сеть\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "7vkhbou-14rI"
      },
      "id": "7vkhbou-14rI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генератор изображений создается на основе класса ImageDataGenerator.\n",
        "# Генератор делит значения всех пикселов изображения на 255.\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# Генератор данных для обучения на основе изображений из каталога\n",
        "train_generator = datagen.flow_from_directory(train_dir,\n",
        "                                              target_size=(img_width, img_height),\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='categorical')\n",
        "\n",
        "# Генератор данных для проверки на основе изображений из каталога\n",
        "val_generator = datagen.flow_from_directory(val_dir,\n",
        "                                            target_size=(img_width, img_height),\n",
        "                                            batch_size=batch_size,\n",
        "                                            class_mode='categorical')\n",
        "\n",
        "# Генератор данных для тестирования на основе изображений из каталога\n",
        "test_generator = datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(img_width, img_height),\n",
        "                                             batch_size=batch_size,\n",
        "                                             class_mode='categorical',\n",
        "                                             shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qrPJsQzR1eU",
        "outputId": "d054643a-6cd3-4cd7-bbd9-7b8337236880"
      },
      "id": "0qrPJsQzR1eU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2800 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n",
            "Found 80 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем модель с использованием генераторов\n",
        "# train_generator - генератор данных для обучения\n",
        "# validation_data - генератор данных для проверки\n",
        "model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=nb_train_samples // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "# Оцениваем качество работы сети с помощью генератора\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1] * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5tE9Ap5R-V_",
        "outputId": "93c2237a-3122-4936-bd4b-d697d611dc40"
      },
      "id": "I5tE9Ap5R-V_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 128s 2s/step - loss: 3.0038 - accuracy: 0.2362 - val_loss: 1.5221 - val_accuracy: 0.2333\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 97s 2s/step - loss: 1.8211 - accuracy: 0.2681 - val_loss: 2.2040 - val_accuracy: 0.2667\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 97s 2s/step - loss: 1.8240 - accuracy: 0.2681 - val_loss: 1.7099 - val_accuracy: 0.2333\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 97s 2s/step - loss: 1.6780 - accuracy: 0.2899 - val_loss: 1.6748 - val_accuracy: 0.2222\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 97s 2s/step - loss: 1.5440 - accuracy: 0.3797 - val_loss: 1.6189 - val_accuracy: 0.5111\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 100s 2s/step - loss: 1.3749 - accuracy: 0.4174 - val_loss: 1.0961 - val_accuracy: 0.5444\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 99s 2s/step - loss: 1.6866 - accuracy: 0.3188 - val_loss: 2.2644 - val_accuracy: 0.4556\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 99s 2s/step - loss: 2.1370 - accuracy: 0.3551 - val_loss: 1.2038 - val_accuracy: 0.3889\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 99s 2s/step - loss: 1.2549 - accuracy: 0.4696 - val_loss: 1.1858 - val_accuracy: 0.4333\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 99s 2s/step - loss: 1.4648 - accuracy: 0.4058 - val_loss: 1.1399 - val_accuracy: 0.4889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Аккуратность на тестовых данных: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mpg = model.predict_generator(test_generator, len(test_generator))\n",
        "y_test = test_generator.classes\n",
        "y_pred = np.array([np.argmax(mpg[i, :]) for i in range(mpg.shape[0])])\n",
        "cl_names = list(train_generator.class_indices)\n",
        "y_t = np.array(cl_names)[y_test]\n",
        "y_p = np.array(cl_names)[y_pred]\n",
        "mtrs = metrics.classification_report(y_t, y_p)\n",
        "print(mtrs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkkv8NOdSDvO",
        "outputId": "cdf38a83-9e02-4ed6-d287-45e89ea446ed"
      },
      "id": "jkkv8NOdSDvO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        20\n",
            "           1       1.00      0.80      0.89        20\n",
            "           3       0.00      0.00      0.00        20\n",
            "           8       0.31      1.00      0.48        20\n",
            "\n",
            "    accuracy                           0.45        80\n",
            "   macro avg       0.33      0.45      0.34        80\n",
            "weighted avg       0.33      0.45      0.34        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn.metrics.confusion_matrix(y_t,y_p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5cdE7VW0Ct-",
        "outputId": "9f95ff6f-70f1-4320-93fb-7750ef6a9d35"
      },
      "id": "O5cdE7VW0Ct-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, 20],\n",
              "       [ 0, 16,  0,  4],\n",
              "       [ 0,  0,  0, 20],\n",
              "       [ 0,  0,  0, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 383
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "lab12",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}